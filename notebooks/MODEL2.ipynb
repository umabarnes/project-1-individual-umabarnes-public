{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Modeling\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+---+----+----+------+---------+------------+----------+-----------+\n",
      "|      date|hour|count|wnd| tmp| dew|   atm|bus_count|subway_count|is_weekday|day_of_week|\n",
      "+----------+----+-----+---+----+----+------+---------+------------+----------+-----------+\n",
      "|2023-07-01|   0|33809|0.0|23.9|13.3|1017.1|        1|           5|     false|          7|\n",
      "|2023-07-01|   1|26914|0.0|23.3|13.3|1017.6|        1|           7|     false|          7|\n",
      "|2023-07-01|   2|21115|0.0|23.3|12.8|1017.8|        2|           2|     false|          7|\n",
      "|2023-07-01|   3|17051|3.1|22.8|12.8|1017.7|        0|           1|     false|          7|\n",
      "|2023-07-01|   4|14159|1.5|22.8|11.7|1017.4|        0|          11|     false|          7|\n",
      "+----------+----+-----+---+----+----+------+---------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the CSV file\n",
    "csv_file_path = \"../data/curated/merged2.csv\"\n",
    "\n",
    "# Read the CSV file\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+------------------+\n",
      "|      date|hour|count|        prediction|\n",
      "+----------+----+-----+------------------+\n",
      "|2023-07-01|   0|33809| 17027.71414723526|\n",
      "|2023-07-01|   1|26914|17838.070293373992|\n",
      "|2023-07-01|   2|21115| 19648.18898727853|\n",
      "|2023-07-01|   3|17051| 20888.89370842273|\n",
      "|2023-07-01|   4|14159|20476.862566856715|\n",
      "|2023-07-01|   5|11827|21752.542017829688|\n",
      "|2023-07-01|   6|13210| 23677.31930723403|\n",
      "|2023-07-01|   7|15708|24194.861520262308|\n",
      "|2023-07-01|   8|19051|26270.051561371412|\n",
      "|2023-07-01|   9|22786|26571.503625225894|\n",
      "|2023-07-01|  10|24856|27007.465011506785|\n",
      "|2023-07-01|  11|27103|28039.734445259703|\n",
      "|2023-07-01|  12|28176|29763.804240957063|\n",
      "|2023-07-01|  13|28834|30281.159622555904|\n",
      "|2023-07-01|  14|30289|31129.799275748675|\n",
      "|2023-07-01|  15|31437|32579.489564313262|\n",
      "|2023-07-01|  16|31861| 33414.16286298814|\n",
      "|2023-07-01|  17|33489| 34525.25486281747|\n",
      "|2023-07-01|  18|35206| 35951.61577014308|\n",
      "|2023-07-01|  19|35360| 36705.52048666443|\n",
      "+----------+----+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Coefficients: [1017.2604411449781,159.45188812697305,-46.54902889220219,205.77397190563929,-117.41685617078346,-4904.71824623587]\n",
      "Intercept: 18521.54624670717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/25 15:02:00 WARN Instrumentation: [47d859c5] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Assemble the features into a single vector column named \"features\"\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"hour\", \"wnd\", \"tmp\", \"bus_count\", \"subway_count\",\"is_weekday\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Define the Lasso regression model\n",
    "lasso = LinearRegression(featuresCol=\"features\", labelCol=\"count\", elasticNetParam=1.0)\n",
    "\n",
    "# Create a pipeline with the assembler and the Lasso model\n",
    "pipeline = Pipeline(stages=[assembler, lasso])\n",
    "\n",
    "# Fit the model to the data\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Make predictions on the same DataFrame\n",
    "predictions = model.transform(df)\n",
    "\n",
    "# Show the predictions alongside the original data\n",
    "predictions.select(\"date\", \"hour\", \"count\", \"prediction\").show()\n",
    "\n",
    "# Optionally, view the model coefficients and intercept\n",
    "linear_model = model.stages[-1]  # The last stage is the linear regression model\n",
    "print(\"Coefficients: \" + str(linear_model.coefficients))\n",
    "print(\"Intercept: \" + str(linear_model.intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 5596.955057668044\n",
      "Mean Squared Error (MSE): 53959470.87259217\n",
      "Root Mean Squared Error (RMSE): 7345.71105289285\n",
      "R-squared (R²): 0.5140323688923978\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model using different metrics\n",
    "evaluator = RegressionEvaluator(labelCol=\"count\", predictionCol=\"prediction\")\n",
    "\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# R-squared (R²)\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7863.158818957534\n",
      "Mean Squared Error (MSE): 94467597.39571145\n",
      "Root Mean Squared Error (RMSE): 9719.444294593774\n",
      "R-squared (R²): 0.14920969793758843\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Assemble the features into a single vector\n",
    "feature_columns = ['wnd', 'tmp', 'dew', 'atm', 'bus_count', 'subway_count', 'is_weekday', 'day_of_week']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "df_with_features = assembler.transform(df)\n",
    "\n",
    "# Initialize Lasso linear regression model\n",
    "lasso = LinearRegression(labelCol='count', featuresCol='features', regParam=0.1, elasticNetParam=1.0)\n",
    "\n",
    "# Fit the model\n",
    "lasso_model = lasso.fit(df_with_features)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lasso_model.transform(df_with_features)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(labelCol='count', predictionCol='prediction', metricName='r2')\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "mae = evaluator.evaluate(predictions, {evaluator.metricName: \"mae\"})\n",
    "mse = evaluator.evaluate(predictions, {evaluator.metricName: \"mse\"})\n",
    "rmse = evaluator.evaluate(predictions, {evaluator.metricName: \"rmse\"})\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Mean Absolute Error (MAE): 7863.145888526261\n",
      "Lasso Mean Squared Error (MSE): 94467597.03789735\n",
      "Lasso Root Mean Squared Error (RMSE): 9719.444276186645\n",
      "Lasso R-squared (R²): 0.14920970116011956\n",
      "Random Forest Mean Absolute Error (MAE): 7454.456779797125\n",
      "Random Forest Mean Squared Error (MSE): 85782247.53110453\n",
      "Random Forest Root Mean Squared Error (RMSE): 9261.870628069933\n",
      "Random Forest R-squared (R²): 0.22743134894320727\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "# Assemble features into a vector\n",
    "feature_columns = ['wnd', 'tmp', 'dew', 'atm', 'bus_count', 'subway_count', 'is_weekday', 'day_of_week']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol='features')\n",
    "df_with_features = assembler.transform(df)\n",
    "\n",
    "# Optional: Standardize features\n",
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features', withStd=True, withMean=True)\n",
    "scaler_model = scaler.fit(df_with_features)\n",
    "df_scaled = scaler_model.transform(df_with_features)\n",
    "\n",
    "# Define and train Lasso Linear Regression model with hyperparameter tuning\n",
    "lasso = LinearRegression(labelCol='count', featuresCol='scaled_features', elasticNetParam=1.0)  # Lasso with elasticNetParam=1.0\n",
    "\n",
    "# Create a parameter grid for tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(lasso.regParam, [0.01, 0.1, 1.0]).build()\n",
    "\n",
    "# Create a CrossValidator\n",
    "crossval = CrossValidator(estimator=lasso,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=RegressionEvaluator(labelCol='count', predictionCol='prediction'),\n",
    "                           numFolds=5)\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters\n",
    "cv_model = crossval.fit(df_scaled)\n",
    "cv_predictions = cv_model.transform(df_scaled)\n",
    "\n",
    "# Evaluate the Lasso model\n",
    "cv_evaluator = RegressionEvaluator(labelCol='count', predictionCol='prediction', metricName='r2')\n",
    "r2 = cv_evaluator.evaluate(cv_predictions)\n",
    "mae = cv_evaluator.evaluate(cv_predictions, {cv_evaluator.metricName: \"mae\"})\n",
    "mse = cv_evaluator.evaluate(cv_predictions, {cv_evaluator.metricName: \"mse\"})\n",
    "rmse = cv_evaluator.evaluate(cv_predictions, {cv_evaluator.metricName: \"rmse\"})\n",
    "\n",
    "print(f\"Lasso Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Lasso Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Lasso Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Lasso R-squared (R²): {r2}\")\n",
    "\n",
    "# Alternative Model: Random Forest Regressor\n",
    "rf = RandomForestRegressor(labelCol='count', featuresCol='scaled_features')\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = rf.fit(df_scaled)\n",
    "rf_predictions = rf_model.transform(df_scaled)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "rf_evaluator = RegressionEvaluator(labelCol='count', predictionCol='prediction', metricName='r2')\n",
    "rf_r2 = rf_evaluator.evaluate(rf_predictions)\n",
    "rf_mae = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"mae\"})\n",
    "rf_mse = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"mse\"})\n",
    "rf_rmse = rf_evaluator.evaluate(rf_predictions, {rf_evaluator.metricName: \"rmse\"})\n",
    "\n",
    "print(f\"Random Forest Mean Absolute Error (MAE): {rf_mae}\")\n",
    "print(f\"Random Forest Mean Squared Error (MSE): {rf_mse}\")\n",
    "print(f\"Random Forest Root Mean Squared Error (RMSE): {rf_rmse}\")\n",
    "print(f\"Random Forest R-squared (R²): {rf_r2}\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('.venv1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc19f976deae78a4b8dd1c0db37710e451de00dcd2e448b10d5869a2fb538e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
